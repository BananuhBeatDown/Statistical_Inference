---
title: "Statistical Inference Project 1"
author: "Matthew Green"
date: "June 30, 2016"
output: html_document
---

# Exectutive Summary

This analysis is for the Statistical Inference class on Coursera that is part of the Johns Hopkins University specialization in Data Science. We'll be investigating the exponential distribution in R and compare it with the Central Limit Theorem using simulated datasets and visuals.

## Simulation

The r code creates a 40x1000 matrix stored in __expSims__ using the replicate and rexp functions and the __n, lambda, and sims__ variables defined in the set-up portion of the code. The apply function was then used to create __expMeans__, a vector containing the means from 1000 different simulations. The mean of __expMeans__ was then taken and stored in __sampleMean__.

```{r}

# Set-up
set.seed(34)
lambda   <- 0.2
n        <- 40
sims     <- 1000
theoMean <- 1 / lambda
sd       <- 1 / lambda

# Simulations
expSims   <- replicate(sims, rexp(n, lambda))
expMeans <- apply(expSims, 2, mean)
expMeans <- data.frame(expMeans)
sampleMean <- mean(expMeans$expMeans)

```

## Task 1

Show the sample mean and compare it to the theoretical mean of the distribution.

```{r, echo=FALSE, warning=FALSE}
library(ggplot2)

meansDistHist <- ggplot(data = expMeans, aes(x = expMeans)) +
  geom_histogram(breaks=seq(2, 8, by=1), col="black", fill="red", alpha = 0.2) +
  geom_vline(aes(xintercept = theoMean, col="blue"), size=1, show.legend = TRUE) + 
  geom_vline(aes(xintercept = sampleMean, colour="green"), size = 1, show.legend = TRUE) +
  scale_colour_manual(name="Mean Type", values = c(theoMean, sampleMean), labels = c("Theo", "Sample")) +
  theme_gray(base_size = 15) + 
  labs(x = "Means", fontface = "bold") +
  labs(y = "Count") +
  labs(title = "Dist of Means of Random Exponential Simulations")
meansDistHist

```

According to the Law of Large numbers, the average of the results obtained from a large number of trials should be close to the expected value, and will tend to become closer as more trials are performed. The LLN is important because it "guarantees" stable long-term results for the averages of some random events.

## Task 2

Show how variable the sample is (via variance) and compare it to the theoretical variance of the distribution.

```{r, warning=FALSE}

# Task 2
sdTheo = (1 / lambda) * (1 / sqrt(n))
sdSamp = sd(expMeans$expMeans)
varTheo = (sdTheo) ^2
varSamp = sd(expMeans$expMeans) ^2
```

```{r, echo=FALSE, warning=FALSE}

cat("The theoretical variance is:", varTheo)
cat("The sample variance of 100 simulations is:", 0.5687444)
cat("The sample variance of 1000 simulations is:", varSamp)
cat("The sample variance of 10000 simulations is:", 0.613893)
print("The 'sims' variable was changed to 100 and 10000 accordingly to calculate the 100 and 10000 simulation variances.")

```

As the sample size of the means increase, the sample variance and the theoretical variance converge.

## Task 3

Show that the distribution is approximately normal. Focus on the difference between the distribution of a large collection of random exponentials and the distribution of a large collection of averages of 40 exponentials.

```{r, echo=FALSE, warning=FALSE} 

# Task 3
rexp1000 <- rexp(sims, lambda)
rexp1000 <- data.frame("exponentials" = rexp1000)
                       
rexp1000DistHist <- ggplot(data = rexp1000, aes(x = exponentials)) +
  geom_histogram(breaks=seq(0, 40, by=1), col="black", fill="red", alpha = 0.4) +
  geom_vline(aes(xintercept = theoMean, col="blue"), size=1, show.legend = TRUE) + 
  geom_vline(linetype = 2,aes(xintercept = mean(rexp1000$exponentials), col="green"), size = 1, show.legend = TRUE) +
  scale_colour_manual(name="Mean Type", values = c(theoMean, sampleMean), labels = c("Theo", "Sample")) +
  theme_gray(base_size = 15) + 
  labs(x = "Exponentials", fontface = "bold") +
  labs(y = "Count") +
  labs(title = "Dist of a Large Collection of Random Exponentials")
rexp1000DistHist

```

```{r, echo=FALSE, warning=FALSE} 
meansDistHist
```

```{r, echo=FALSE, warning=FALSE}
normRexpMeans <- data.frame("nrm" = (expMeans$expMeans - theoMean) / sqrt(n))
meanNRM <- mean(normRexpMeans$nrm)

normMeansDistHist <- ggplot(data = normRexpMeans, aes(x = nrm)) +
  geom_histogram(breaks=seq(-0.4, 0.4, by=0.1), col="black", fill="red", alpha = 0.2) +
  geom_vline(aes(xintercept = 0, col="blue"), size=1, show.legend = TRUE) + 
  geom_vline(aes(xintercept = meanNRM, colour="green"), size = 1, show.legend = TRUE) +
  scale_colour_manual(name="Mean Type", values = c(theoMean, sampleMean), labels = c("Theo", "Sample")) +
  theme_gray(base_size = 15) + 
  labs(x = "Means", fontface = "bold") +
  labs(y = "Count") +
  labs(title = "Dist of Normalized Means of Random Exponentials")
normMeansDistHist

```

The histogram depicting the distribution of random exponentials would lead the student to believe that the distribution isn't normalized. However, when we normalized the means we used to create the distribution of normalized means histogram in __task 1__ notice that both the sample and theoretical means are now 0, and the structure of this histogram matches that of a normal density graph. If we would have run more simulations and/or had a larger n the graph would look even more normal around the mean.
